{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Ensure that your notebook can find the Dataset and Model classes:\n",
    "# you can either add that folder to PYTHONPATH or copy the files into the notebook directory.\n",
    "import sys\n",
    "sys.path.append('.')  # Adjust this path if the files are located in a subdirectory\n",
    "\n",
    "# Now import the Dataset and Model\n",
    "from src.dataloader import SimpleTokenDataset\n",
    "from src.transformer import SANETokenAutoencoder\n",
    "\n",
    "# GPU stability settings (optional but recommended)\n",
    "# Disable Flash Attention to avoid potential compatibility issues\n",
    "os.environ[\"PYTORCH_ENABLE_FLASH_ATTN\"] = \"0\"\n",
    "# Make CUDA operations deterministic for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "# Disable CuDNN benchmark mode to prevent dynamic algorithm selection (ensures consistent behavior)\n",
    "torch.backends.cudnn.benchmark     = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# Paths to Token and Position Files\n",
    "# -----------------------------------------------------------------------------\n",
    "# Directory containing token/position data files. Adjust this path if your data\n",
    "# resides elsewhere.\n",
    "token_dir = \"../crawled_models_first_5_levels\"\n",
    "\n",
    "# List of model identifier strings corresponding to the directories or checkpoint\n",
    "# names you want to load. Update this list if you have multiple models or \n",
    "# different naming conventions.\n",
    "model_ids = [\"asteroid6__base_000_000_000__checkpoints__final\"]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Window Size and Batch Size\n",
    "# -----------------------------------------------------------------------------\n",
    "# The length of each input window (number of tokens) that the model processes.\n",
    "window_size = 256\n",
    "\n",
    "# Number of samples to load per batch during training or evaluation.\n",
    "batch_size = 8\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Checkpoint File Path\n",
    "# -----------------------------------------------------------------------------\n",
    "# Path to a saved model checkpoint file (e.g., \"checkpoint_epoch05.pt\"). This is\n",
    "# used to resume training or perform inference from a previously saved state.\n",
    "checkpoint_path = \"checkpoint_epoch05.pt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that SimpleTokenDataset provides the fields:\n",
    "# 'tokens', 'abs_norm', 'p_norm', and 'levels'.\n",
    "dataset = SimpleTokenDataset(\n",
    "    token_dir=token_dir,    # Directory where token/position files are stored\n",
    "    model_ids=model_ids,    # List of model identifiers to load data from\n",
    "    window_size=window_size,# Number of tokens per input window\n",
    "    augment=False           # Disable any data augmentation when evaluating\n",
    ")\n",
    "\n",
    "# Wrap the dataset in a DataLoader for batching and parallel data loading.\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,  # Number of samples per batch\n",
    "    shuffle=True,           # Enable shuffling of data each epoch\n",
    "                            # (If evaluating without randomness, set to False)\n",
    "    num_workers=4,          # Spawn 4 subprocesses to load data in parallel\n",
    "    pin_memory=True         # Copy tensors into CUDA pinned memory before returning\n",
    "                            # (speeds up host-to-GPU transfers)\n",
    ")\n",
    "\n",
    "# Print out the total number of windows in the dataset\n",
    "print(f\"Dataset size (number of windows): {len(dataset)}\")\n",
    "# Print out how many batches are created given the batch size\n",
    "print(f\"Number of batches (batch_size={batch_size}): {len(dataloader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the SANETokenAutoencoder model with specified hyperparameters:\n",
    "# - token_dim: Dimensionality of each input token (e.g., 2 for (x, y) coordinates)\n",
    "# - d_model: Feature dimension inside the Transformer layers\n",
    "# - nhead: Number of attention heads in each multi-head attention layer\n",
    "# - num_layers: Number of Transformer encoder/decoder layers\n",
    "# - dim_feedforward: Hidden dimension of the feedforward sublayers\n",
    "# - dropout: Dropout probability to use between layers\n",
    "# - level_embed_dim: Embedding dimension for the 'levels' feature\n",
    "model = SANETokenAutoencoder(\n",
    "    token_dim=2,\n",
    "    d_model=64,\n",
    "    nhead=4,\n",
    "    num_layers=2,\n",
    "    dim_feedforward=256,\n",
    "    dropout=0.1,\n",
    "    level_embed_dim=16\n",
    ").to(device)  # Move the model to the selected device (GPU or CPU)\n",
    "\n",
    "# Verify that the checkpoint file exists before attempting to load it\n",
    "if not os.path.isfile(checkpoint_path):\n",
    "    raise FileNotFoundError(f\"Checkpoint file '{checkpoint_path}' not found.\")\n",
    "\n",
    "# Load the checkpoint's state dictionary, mapping tensors to the correct device\n",
    "state_dict = torch.load(checkpoint_path, map_location=device)\n",
    "# Load the weights into the model\n",
    "model.load_state_dict(state_dict)\n",
    "# Set the model to evaluation mode (disables dropout, uses running stats for batchnorm, etc.)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Checkpoint '{checkpoint_path}' loaded. Model set to evaluation mode.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "    for batch in tqdm(dataloader, desc=\"Evaluating reconstruction\", unit=\"Batch\"):\n",
    "        # Move each field in the batch to the selected device (GPU or CPU)\n",
    "        tokens   = batch[\"tokens\"].to(device)   # Shape: [B, W, 2]\n",
    "        abs_norm = batch[\"abs_norm\"].to(device) # Shape: [B, W, 1]\n",
    "        p_norm   = batch[\"p_norm\"].to(device)   # Shape: [B, W, 1]\n",
    "        levels   = batch[\"levels\"].to(device)   # Shape: [B, W]\n",
    "\n",
    "        # Forward pass through the model to reconstruct the input tokens\n",
    "        recon = model(tokens, abs_norm, p_norm, levels)  # Output shape: [B, W, 2]\n",
    "\n",
    "        # Compute MSE per token (no reduction) to get a tensor of shape [B, W, 2]\n",
    "        mse_per_token = F.mse_loss(recon, tokens, reduction=\"none\")  # [B, W, 2]\n",
    "        # Average MSE across both token dimensions (W and 2) to get one value per window\n",
    "        mse_per_window = mse_per_token.mean(dim=(1, 2))  # Shape: [B]\n",
    "        # Compute the average MSE across all windows in this batch\n",
    "        avg_mse = mse_per_window.mean().item()\n",
    "\n",
    "        print(f\"\\nAverage MSE over the first batch: {avg_mse:.6e}\\n\")\n",
    "        break  # Only process the first batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first window in the batch (window_idx = 0)\n",
    "window_idx = 0\n",
    "\n",
    "# The 'tokens' and 'recon' tensors have shape [B, W, 2].\n",
    "# Move them to CPU and reshape explicitly to [batch_size, window_size, 2] \n",
    "orig_batch = tokens.cpu().view(batch_size, window_size, 2)\n",
    "recon_batch = recon.cpu().view(batch_size, window_size, 2)\n",
    "\n",
    "# Extract the first window (index 0) from both original and reconstructed batches.\n",
    "# Each window has shape [window_size, 2].\n",
    "orig_window = orig_batch[window_idx]    # Shape: [W, 2]\n",
    "recon_window = recon_batch[window_idx]  # Shape: [W, 2]\n",
    "\n",
    "# Create a figure with two subplots (one for each token dimension).\n",
    "# figsize=(8, 6) sets the overall figure size in inches.\n",
    "# sharex=True makes the x-axis shared between the two plots.\n",
    "fig, axes = plt.subplots(2, 1, figsize=(8, 6), sharex=True)\n",
    "\n",
    "# Prepare the x-axis values: a list from 0 to window_size-1\n",
    "x_axis = list(range(window_size))\n",
    "\n",
    "# --- Plot for Dimension 0 ---\n",
    "# Plot the original token values in dimension 0 as a solid line.\n",
    "axes[0].plot(x_axis, orig_window[:, 0], label=\"Original Dim 0\", linewidth=1)\n",
    "# Plot the reconstructed token values in dimension 0 as a dashed line.\n",
    "axes[0].plot(x_axis, recon_window[:, 0], \"--\", label=\"Recon Dim 0\", linewidth=1)\n",
    "axes[0].set_ylabel(\"Value\")            # Label for the y-axis\n",
    "axes[0].set_title(\"Original vs. Reconstruction (Dim 0)\")  # Title of the subplot\n",
    "axes[0].legend()                        # Show legend\n",
    "axes[0].grid(True)                      # Enable grid lines for readability\n",
    "\n",
    "# --- Plot for Dimension 1 ---\n",
    "# Plot the original token values in dimension 1 as a solid line.\n",
    "axes[1].plot(x_axis, orig_window[:, 1], label=\"Original Dim 1\", linewidth=1)\n",
    "# Plot the reconstructed token values in dimension 1 as a dashed line.\n",
    "axes[1].plot(x_axis, recon_window[:, 1], \"--\", label=\"Recon Dim 1\", linewidth=1)\n",
    "axes[1].set_xlabel(\"Token index in window (0 â€¦ window_size-1)\")  # Label for the x-axis\n",
    "axes[1].set_ylabel(\"Value\")            # Label for the y-axis\n",
    "axes[1].set_title(\"Original vs. Reconstruction (Dim 1)\")  # Title of the subplot\n",
    "axes[1].legend()                        # Show legend\n",
    "axes[1].grid(True)                      # Enable grid lines\n",
    "\n",
    "# Adjust subplot layouts to prevent overlap and make the figure look neat.\n",
    "plt.tight_layout()\n",
    "# Display the figure with both subplots.\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to use `tokens`, `recon`, and `levels` from the current workspace.\n",
    "# If they do not exist, generate dummy data instead.\n",
    "try:\n",
    "    # Retrieve batch size (B), window size (W), and token dimension (_) from `tokens`\n",
    "    B, W, _ = tokens.shape   # batch_size, window_size, token_dim\n",
    "\n",
    "    # Move tensors to CPU, reshape to [B, W, 2], and convert to NumPy arrays\n",
    "    original_batch = tokens.cpu().view(B, W, 2).numpy()  \n",
    "    recon_batch    = recon.cpu().view(B, W, 2).numpy()  \n",
    "    levels_batch   = levels.cpu().view(B, W).numpy()    # Shape: [B, W]\n",
    "\n",
    "    # Select the first window in the batch (index 0)\n",
    "    window_idx = 0\n",
    "    orig_window  = original_batch[window_idx]  # Shape: [W, 2]\n",
    "    recon_window = recon_batch[window_idx]     # Shape: [W, 2]\n",
    "    level_window = levels_batch[window_idx]    # Shape: [W]\n",
    "\n",
    "except NameError:\n",
    "    # If `tokens`, `recon`, or `levels` are not found, create dummy data\n",
    "    W = 256  # Window size\n",
    "    # Generate random original token values [W, 2]\n",
    "    orig_window = np.random.randn(W, 2)\n",
    "    # Create reconstructed values by adding small Gaussian noise\n",
    "    recon_window = orig_window + (np.random.randn(W, 2) * 0.01)  \n",
    "    # Create dummy levels, all set to 0\n",
    "    level_window = np.zeros(W, dtype=int)  \n",
    "\n",
    "# Build a pandas DataFrame with five columns:\n",
    "#   - orig_dim0: Original values for token dimension 0\n",
    "#   - recon_dim0: Reconstructed values for token dimension 0\n",
    "#   - orig_dim1: Original values for token dimension 1\n",
    "#   - recon_dim1: Reconstructed values for token dimension 1\n",
    "#   - level:    Level index for each token in the window\n",
    "df = pd.DataFrame({\n",
    "    'orig_dim0': orig_window[:, 0],\n",
    "    'recon_dim0': recon_window[:, 0],\n",
    "    'orig_dim1': orig_window[:, 1],\n",
    "    'recon_dim1': recon_window[:, 1],\n",
    "    'level': level_window\n",
    "})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
